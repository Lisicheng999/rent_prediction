{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用深度学习方法进行建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Address    Rent  Beds  Baths  \\\n",
      "0  The Gate Tower 2, The Gate Tower, Shams Gate D...  124000     3      4   \n",
      "1                Water's Edge, Yas Island, Abu Dhabi  140000     3      4   \n",
      "2            Al Raha Lofts, Al Raha Beach, Abu Dhabi   99000     2      3   \n",
      "\n",
      "        Type  Area_in_sqft  Rent_per_sqft Rent_category Frequency  \\\n",
      "0  Apartment          1785      69.467787        Medium    Yearly   \n",
      "1  Apartment          1422      98.452883        Medium    Yearly   \n",
      "2  Apartment          1314      75.342466        Medium    Yearly   \n",
      "\n",
      "    Furnishing   Purpose Posted_date  Age_of_listing_in_days        Location  \\\n",
      "0  Unfurnished  For Rent  2024-03-07                      45  Al Reem Island   \n",
      "1  Unfurnished  For Rent  2024-03-08                      44      Yas Island   \n",
      "2    Furnished  For Rent  2024-03-21                      31   Al Raha Beach   \n",
      "\n",
      "        City   Latitude  Longitude  \n",
      "0  Abu Dhabi  24.493598  54.407841  \n",
      "1  Abu Dhabi  24.494022  54.607372  \n",
      "2  Abu Dhabi  24.485931  54.600939  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data=pd.read_csv(\"dubai_properties.csv\")\n",
    "data.dropna(inplace=True)\n",
    "print(data.head(3))\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address                    object\n",
      "Rent                        int64\n",
      "Beds                        int64\n",
      "Baths                       int64\n",
      "Type                       object\n",
      "Area_in_sqft                int64\n",
      "Rent_per_sqft             float64\n",
      "Rent_category              object\n",
      "Frequency                  object\n",
      "Furnishing                 object\n",
      "Purpose                    object\n",
      "Posted_date                object\n",
      "Age_of_listing_in_days      int64\n",
      "Location                   object\n",
      "City                       object\n",
      "Latitude                  float64\n",
      "Longitude                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 查看数据类型\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 编码分类特征\n",
    "\n",
    "# for column, le in label_encoders.items():\n",
    "#     num_classes = len(le.classes_)\n",
    "#     print(f\"列 '{column}' 有 {num_classes} 种分类。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Address    Rent  Beds  Baths  Type  Area_in_sqft  Rent_per_sqft  \\\n",
      "0     3905  124000     3      4     0          1785      69.467787   \n",
      "1     4219  140000     3      4     0          1422      98.452883   \n",
      "\n",
      "   Rent_category  Frequency  Furnishing  Purpose  Posted_date  \\\n",
      "0              2          0           1        0          503   \n",
      "1              2          0           1        0          504   \n",
      "\n",
      "   Age_of_listing_in_days  Location  City   Latitude  Longitude  \n",
      "0                      45       135     0  24.493598  54.407841  \n",
      "1                      44       353     0  24.494022  54.607372  \n",
      "Address                     int32\n",
      "Rent                        int64\n",
      "Beds                        int64\n",
      "Baths                       int64\n",
      "Type                        int32\n",
      "Area_in_sqft                int64\n",
      "Rent_per_sqft             float64\n",
      "Rent_category               int32\n",
      "Frequency                   int32\n",
      "Furnishing                  int32\n",
      "Purpose                     int32\n",
      "Posted_date                 int32\n",
      "Age_of_listing_in_days      int64\n",
      "Location                    int32\n",
      "City                        int32\n",
      "Latitude                  float64\n",
      "Longitude                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## 对非数值类型的特征进行分类编码\n",
    "\n",
    "# 创建一个字典来存储每个特征的编码器\n",
    "encoders = {}\n",
    "# 遍历每列\n",
    "for column in data.columns:\n",
    "    # 如果是对象类型（通常是字符串或混合类型）\n",
    "    if data[column].dtype == object:\n",
    "        # 创建一个 LabelEncoder\n",
    "        encoder = LabelEncoder()\n",
    "        # 对当前列进行编码\n",
    "        data[column] = encoder.fit_transform(data[column])\n",
    "        # 保存编码器以便后续使用\n",
    "        encoders[column] = encoder\n",
    "    elif data[column].dtype == 'int64' or data[column].dtype == 'float64':\n",
    "        # 数值类型，不需要编码\n",
    "        pass\n",
    "    else:\n",
    "        print(f\"Warning: Unhandled data type for column '{column}'\")\n",
    "        \n",
    "# 查看数据\n",
    "print(data.head(2))\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Address  Beds  Baths  Type  Area_in_sqft  Rent_per_sqft  Rent_category  \\\n",
      "0     3905     3      4     0          1785      69.467787              2   \n",
      "1     4219     3      4     0          1422      98.452883              2   \n",
      "\n",
      "   Frequency  Furnishing  Purpose  Posted_date  Age_of_listing_in_days  \\\n",
      "0          0           1        0          503                      45   \n",
      "1          0           1        0          504                      44   \n",
      "\n",
      "   Location  City   Latitude  Longitude  \n",
      "0       135     0  24.493598  54.407841  \n",
      "1       353     0  24.494022  54.607372  \n",
      "0    124000\n",
      "1    140000\n",
      "Name: Rent, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 准备特征和目标变量\n",
    "X = data.drop(['Rent'],  axis=1)\n",
    "y = data['Rent']\n",
    "# # 根据分类剔除分类为1的维度\n",
    "# X = X.drop(['Frequency', 'Purpose'], axis=1)\n",
    "print(X.head(2))\n",
    "print(y.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.47687015  0.5381336   0.83981347 -0.53658716 -0.08421462 -0.28621261\n",
      "   1.20988169  0.          0.52157908  0.          0.43296941 -0.40208572\n",
      "  -0.84502384 -1.18090496 -0.74704453 -0.98711226]\n",
      " [ 1.72925982  0.5381336   0.83981347 -0.53658716 -0.20618471  0.14882219\n",
      "   1.20988169  0.          0.52157908  0.          0.44833278 -0.41600607\n",
      "   1.69240706 -1.18090496 -0.7463     -0.68188639]]\n",
      "(73023, 16)\n",
      "(73023,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 使用标准归一化器\n",
    "standard_scaler = StandardScaler()\n",
    "X_scaled = standard_scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled[:2])\n",
    "print(X_scaled.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73023, 1)\n",
      "[[-0.07906335]\n",
      " [-0.02715964]]\n"
     ]
    }
   ],
   "source": [
    "# 归一化正确，将y也归一化处理\n",
    "y_from_to_frame = y.to_frame()\n",
    "print(y_from_to_frame.shape)\n",
    "y_scaled = standard_scaler.fit_transform(y_from_to_frame)\n",
    "print(y_scaled[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26395294 -1.3711756  -1.0110441  -0.5365872  -0.46558115 -0.47449508\n",
      "  -0.0099224   0.          0.5215791   0.          0.5251496  -0.48560783\n",
      "  -1.694714   -1.180905   -0.78964376 -1.0774182 ]\n",
      " [ 1.6480771  -1.3711756  -0.3940916  -0.5365872  -0.52505416  1.6856266\n",
      "   1.2098817   0.         -1.9172548   0.          0.01815861 -0.02623618\n",
      "  -0.12336918  0.35166693  0.4750966   0.3238181 ]\n",
      " [-1.1756327   0.5381336   0.8398135  -0.5365872   0.46280274 -0.2734313\n",
      "  -1.2297266   0.          0.5215791   0.         -1.8100816   1.6302859\n",
      "  -1.0196177  -1.180905   -0.7605115  -0.6917267 ]]\n",
      "训练集特征张量大小 torch.Size([65720, 16])\n",
      "训练集目标张量大小 torch.Size([65720, 1])\n",
      "测试集目标张量大小: torch.Size([7303, 16])\n",
      "测试集目标张量大小: torch.Size([7303, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 划分数据集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.1, random_state=42) # 批量归一化\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42) # 非批量归一化\n",
    "# X_train_tensor = torch.FloatTensor(X_train.values)\n",
    "# y_train_tensor = torch.FloatTensor(y_train.values)\n",
    "# X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "# y_test_tensor = torch.FloatTensor(y_test.values)\n",
    "\n",
    "print(X_train_tensor[:3].numpy())\n",
    "print(\"训练集特征张量大小\", X_train_tensor.size())\n",
    "print(\"训练集目标张量大小\", y_train_tensor.size())\n",
    "print(\"测试集目标张量大小:\", X_test_tensor.size())\n",
    "print(\"测试集目标张量大小:\", y_test_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 构建神经网络\n",
    "class RentPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RentPredictor, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 128)\n",
    "        self.layer3 = nn.Linear(128, 256)\n",
    "        self.layer4 = nn.Linear(256, 64)\n",
    "        self.layer5 = nn.Linear(64, 1)\n",
    "        self.swish = nn.SiLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.swish(self.layer1(x))\n",
    "        x = self.swish(self.layer2(x))\n",
    "        x = self.swish(self.layer3(x))\n",
    "        x = self.swish(self.layer4(x))\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X_train_tensor_gpu: torch.Size([65720, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 将模型放到GPU上运行    \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# 将数据也送到GPU\n",
    "X_train_tensor_gpu = X_train_tensor.to(device)\n",
    "X_test_tensor_gpu = X_test_tensor.to(device)\n",
    "y_train_tensor_gpu = y_train_tensor.to(device)\n",
    "y_test_tensor_gpu = y_test_tensor.to(device)\n",
    "\n",
    "# 创建数据加载器，指定批量大小\n",
    "batch_size = 64\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor_gpu, y_train_tensor_gpu)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor_gpu, y_test_tensor_gpu)\n",
    "train_data_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)  # 关闭打乱\n",
    "\n",
    "# 实例化模型\n",
    "print(f\"shape X_train_tensor_gpu: {X_train_tensor_gpu.shape}\")\n",
    "# print(f\"shape[0] y_test_tensor_gpu: {y_test_tensor_gpu.shape[0]}\")\n",
    "model = RentPredictor(X_train_tensor.shape[1]).to(device)\n",
    "\n",
    "# 定义损失函数\n",
    "criterion = nn.MSELoss()\n",
    "# criterion = nn.SmoothL1Loss()\n",
    "\n",
    "# 定义优化器\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "# optimizer = optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)\n",
    "# optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.NAdam(model.parameters(), lr=0.002, betas=(0.9, 0.999))\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.012095353566110134, Val Loss: 0.5945389866828918\n",
      "Epoch 2/20, Loss: 0.04060831293463707, Val Loss: 0.2734518349170685\n",
      "Epoch 3/20, Loss: 0.019669199362397194, Val Loss: 0.4807438254356384\n",
      "Epoch 4/20, Loss: 0.04686111584305763, Val Loss: 1.4928258657455444\n",
      "Epoch 5/20, Loss: 0.004044565837830305, Val Loss: 0.023443127050995827\n",
      "Epoch 6/20, Loss: 0.0034421945456415415, Val Loss: 0.05145258828997612\n",
      "Epoch 7/20, Loss: 0.0027904645539820194, Val Loss: 0.07660377025604248\n",
      "Epoch 8/20, Loss: 0.007911059074103832, Val Loss: 0.054755281656980515\n",
      "Epoch 9/20, Loss: 0.012032901868224144, Val Loss: 0.049040909856557846\n",
      "Epoch 10/20, Loss: 0.0024616443552076817, Val Loss: 0.02840450592339039\n",
      "Epoch 11/20, Loss: 0.04257536306977272, Val Loss: 0.0290590301156044\n",
      "Epoch 12/20, Loss: 0.0034148492850363255, Val Loss: 0.05139366537332535\n",
      "Epoch 13/20, Loss: 0.004615768324583769, Val Loss: 0.030581526458263397\n",
      "Epoch 14/20, Loss: 0.0045333076268434525, Val Loss: 0.0150968162342906\n",
      "Epoch 15/20, Loss: 0.007055499125272036, Val Loss: 0.008174183778464794\n",
      "Epoch 16/20, Loss: 0.0032126246951520443, Val Loss: 0.008460113778710365\n",
      "Epoch 17/20, Loss: 0.003709143726155162, Val Loss: 0.013740421272814274\n",
      "Epoch 18/20, Loss: 0.01900598406791687, Val Loss: 0.0028707089368253946\n",
      "Epoch 19/20, Loss: 0.0027076201513409615, Val Loss: 0.008412221446633339\n",
      "Epoch 20/20, Loss: 0.003087762976065278, Val Loss: 0.0034693307243287563\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "for epoch in range(epochs):\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    for batch in train_data_loader:\n",
    "        X_batch, y_batch = batch\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    # 评估模式\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in test_data_loader:\n",
    "            y_val_pred = model(X_val_batch)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Val Loss: {val_loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.7457756996154785\n",
      "Test RMSE: 1.3212780952453613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\anaconda3\\envs\\venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([7303, 1, 1])) that is different to the input size (torch.Size([7303, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# 5. 计算指标\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor_gpu)\n",
    "    # print(f\"shape: {y_test_pred.shape}\")\n",
    "    test_loss = criterion(y_test_pred, y_test_tensor_gpu.unsqueeze(1))\n",
    "    # print(f\"shape: {y_test_tensor_gpu.shape}\")\n",
    "    mse = test_loss.item()\n",
    "    rmse = torch.sqrt(test_loss).item()\n",
    "# 打印指标\n",
    "print(f'Test MSE: {mse}')\n",
    "print(f'Test RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.025828503554732932\n",
      "Test RMSE: 0.1607124872395824\n",
      "Test R²: 0.9728032284521262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_val_pred = model(X_test_tensor.to(device))\n",
    "    \n",
    "# 将预测结果从GPU复制到CPU\n",
    "y_val_pred_cpu = y_val_pred.to('cpu')\n",
    "\n",
    "# 将预测结果转换为Numpy数组\n",
    "y_val_pred_numpy = y_val_pred_cpu.numpy()\n",
    "\n",
    "# 安全地使用y_val_pred_numpy作为mean_squared_error的输入\n",
    "mse_lr = mean_squared_error(y_test, y_val_pred_numpy)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_val_pred_numpy)\n",
    "\n",
    "# 打印指标\n",
    "print(f'Test MSE: {mse_lr}')\n",
    "print(f'Test RMSE: {rmse_lr}')\n",
    "print(f'Test R²: {r2_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight: torch.Size([64, 16])\n",
      "layer1.bias: torch.Size([64])\n",
      "layer2.weight: torch.Size([128, 64])\n",
      "layer2.bias: torch.Size([128])\n",
      "layer3.weight: torch.Size([256, 128])\n",
      "layer3.bias: torch.Size([256])\n",
      "layer4.weight: torch.Size([64, 256])\n",
      "layer4.bias: torch.Size([64])\n",
      "layer5.weight: torch.Size([1, 64])\n",
      "layer5.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}:\", param.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反归一化后的预测结果: [[219118.77 ]\n",
      " [ 62046.637]\n",
      " [112171.19 ]\n",
      " [121265.78 ]\n",
      " [134401.89 ]]\n",
      "反归一化后的实际目标值: [[230000.   ]\n",
      " [ 45000.004]\n",
      " [ 90000.   ]\n",
      " [135000.   ]\n",
      " [135000.   ]]\n"
     ]
    }
   ],
   "source": [
    "# 假设 model 是您已经训练好的模型\n",
    "# 选择测试集中的几个样本\n",
    "X_test_sample = X_test_tensor_gpu[:5]  # 选择前5个样本\n",
    "y_test_sample = y_test_tensor_gpu[:5]\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():  # 确保不计算梯度\n",
    "    y_pred_sample = model(X_test_sample)\n",
    "\n",
    "# 将预测结果和实际目标值转换为 NumPy 数组\n",
    "y_pred_sample_np = y_pred_sample.cpu().numpy()\n",
    "y_test_sample_np = y_test_sample.cpu().numpy()\n",
    "\n",
    "# 反归一化\n",
    "y_pred_original = standard_scaler.inverse_transform(y_pred_sample_np)\n",
    "y_test_original = standard_scaler.inverse_transform(y_test_sample_np)\n",
    "\n",
    "# 打印反归一化后的预测结果和实际目标值\n",
    "print('反归一化后的预测结果:', y_pred_original)\n",
    "print('反归一化后的实际目标值:', y_test_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 58945 parameters.\n"
     ]
    }
   ],
   "source": [
    "# 获取模型的所有参数\n",
    "parameters = list(model.parameters())\n",
    "\n",
    "# 将所有参数打包成一个向量\n",
    "parameters_vector = torch.cat([p.view(-1) for p in parameters])\n",
    "\n",
    "# 计算参数量\n",
    "num_parameters = parameters_vector.numel()\n",
    "\n",
    "print(f\"The model has {num_parameters} parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as pre_models/my_model_20240508_012617.pth\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "##保存模型\n",
    "\n",
    "# 获取当前日期和时间\n",
    "current_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 结合模型名称和日期时间\n",
    "model_name = 'my_model'\n",
    "model_file_name = f\"pre_models/{model_name}_{current_time}.pth\"\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model, model_file_name)\n",
    "\n",
    "print(f\"Model saved as {model_file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
